{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2952,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1016260162601626,
      "grad_norm": 11.456524848937988,
      "learning_rate": 9.674796747967481e-05,
      "loss": 10.8419,
      "step": 100
    },
    {
      "epoch": 0.2032520325203252,
      "grad_norm": 7.880049705505371,
      "learning_rate": 9.342818428184282e-05,
      "loss": 5.9885,
      "step": 200
    },
    {
      "epoch": 0.3048780487804878,
      "grad_norm": 7.310698986053467,
      "learning_rate": 9.004065040650407e-05,
      "loss": 5.656,
      "step": 300
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 8.87747573852539,
      "learning_rate": 8.665311653116532e-05,
      "loss": 5.4362,
      "step": 400
    },
    {
      "epoch": 0.508130081300813,
      "grad_norm": 10.129262924194336,
      "learning_rate": 8.326558265582655e-05,
      "loss": 5.3856,
      "step": 500
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 11.646081924438477,
      "learning_rate": 7.987804878048781e-05,
      "loss": 5.352,
      "step": 600
    },
    {
      "epoch": 0.7113821138211383,
      "grad_norm": 14.73586368560791,
      "learning_rate": 7.649051490514906e-05,
      "loss": 5.3395,
      "step": 700
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 8.348320960998535,
      "learning_rate": 7.31029810298103e-05,
      "loss": 5.2682,
      "step": 800
    },
    {
      "epoch": 0.9146341463414634,
      "grad_norm": 7.677361965179443,
      "learning_rate": 6.971544715447155e-05,
      "loss": 5.3203,
      "step": 900
    },
    {
      "epoch": 1.016260162601626,
      "grad_norm": 10.297330856323242,
      "learning_rate": 6.63279132791328e-05,
      "loss": 5.2771,
      "step": 1000
    },
    {
      "epoch": 1.1178861788617886,
      "grad_norm": 9.541475296020508,
      "learning_rate": 6.294037940379403e-05,
      "loss": 5.1545,
      "step": 1100
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 8.592801094055176,
      "learning_rate": 5.955284552845529e-05,
      "loss": 5.2481,
      "step": 1200
    },
    {
      "epoch": 1.321138211382114,
      "grad_norm": 16.6639404296875,
      "learning_rate": 5.616531165311654e-05,
      "loss": 5.1527,
      "step": 1300
    },
    {
      "epoch": 1.4227642276422765,
      "grad_norm": 8.521875381469727,
      "learning_rate": 5.2777777777777784e-05,
      "loss": 5.2058,
      "step": 1400
    },
    {
      "epoch": 1.524390243902439,
      "grad_norm": 11.993267059326172,
      "learning_rate": 4.9390243902439024e-05,
      "loss": 5.1921,
      "step": 1500
    },
    {
      "epoch": 1.6260162601626016,
      "grad_norm": 12.769661903381348,
      "learning_rate": 4.600271002710027e-05,
      "loss": 5.1564,
      "step": 1600
    },
    {
      "epoch": 1.7276422764227641,
      "grad_norm": 9.6134672164917,
      "learning_rate": 4.2615176151761524e-05,
      "loss": 5.0782,
      "step": 1700
    },
    {
      "epoch": 1.8292682926829267,
      "grad_norm": 8.665242195129395,
      "learning_rate": 3.922764227642276e-05,
      "loss": 5.0799,
      "step": 1800
    },
    {
      "epoch": 1.9308943089430894,
      "grad_norm": 10.322342872619629,
      "learning_rate": 3.584010840108401e-05,
      "loss": 5.2097,
      "step": 1900
    },
    {
      "epoch": 2.032520325203252,
      "grad_norm": 14.993104934692383,
      "learning_rate": 3.245257452574526e-05,
      "loss": 5.1038,
      "step": 2000
    },
    {
      "epoch": 2.1341463414634148,
      "grad_norm": 10.97720718383789,
      "learning_rate": 2.9065040650406507e-05,
      "loss": 5.0706,
      "step": 2100
    },
    {
      "epoch": 2.2357723577235773,
      "grad_norm": 11.499841690063477,
      "learning_rate": 2.567750677506775e-05,
      "loss": 5.1034,
      "step": 2200
    },
    {
      "epoch": 2.33739837398374,
      "grad_norm": 8.570859909057617,
      "learning_rate": 2.2289972899728996e-05,
      "loss": 5.1097,
      "step": 2300
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 13.142242431640625,
      "learning_rate": 1.8902439024390246e-05,
      "loss": 5.0556,
      "step": 2400
    },
    {
      "epoch": 2.540650406504065,
      "grad_norm": 13.639002799987793,
      "learning_rate": 1.5514905149051493e-05,
      "loss": 5.0871,
      "step": 2500
    },
    {
      "epoch": 2.642276422764228,
      "grad_norm": 12.157094955444336,
      "learning_rate": 1.2127371273712736e-05,
      "loss": 4.9632,
      "step": 2600
    },
    {
      "epoch": 2.7439024390243905,
      "grad_norm": 13.52064037322998,
      "learning_rate": 8.739837398373985e-06,
      "loss": 5.0296,
      "step": 2700
    },
    {
      "epoch": 2.845528455284553,
      "grad_norm": 10.9877347946167,
      "learning_rate": 5.35230352303523e-06,
      "loss": 5.0295,
      "step": 2800
    },
    {
      "epoch": 2.9471544715447155,
      "grad_norm": 11.328095436096191,
      "learning_rate": 1.964769647696477e-06,
      "loss": 5.1011,
      "step": 2900
    }
  ],
  "logging_steps": 100,
  "max_steps": 2952,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0064272438591488e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
